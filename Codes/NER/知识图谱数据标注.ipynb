{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Download Path：     https://hershey.dbi.udel.edu/textmining/export/\n",
    "#site    iTextMine: integrated text-mining system for large-scale knowledge extraction from the literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预训练模型GLoVE \n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_pmc = pd.read_json('rlims.pmc.json',lines=True)\n",
    "'''\n",
    "设置实体类型标签\n",
    "B_Protein蛋白质标签\n",
    "B_Trigger触发器标签\n",
    "'''\n",
    "tag2id = {\n",
    "    'O':1,\n",
    "    'B_Protein':2,\n",
    "    'B_Site':3,\n",
    "    'B_SiteOther':4,\n",
    "    'B_Trigger':5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>article_type</th>\n",
       "      <th>docId</th>\n",
       "      <th>entity</th>\n",
       "      <th>fig_id</th>\n",
       "      <th>fig_lable</th>\n",
       "      <th>id</th>\n",
       "      <th>parent</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pmid</th>\n",
       "      <th>relation</th>\n",
       "      <th>sec_type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>table_id</th>\n",
       "      <th>table_lable</th>\n",
       "      <th>text</th>\n",
       "      <th>title_offset</th>\n",
       "      <th>type</th>\n",
       "      <th>xml_sec_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'$oid': '5bb1845bb5e292a71605ac5c'}</td>\n",
       "      <td>research-article</td>\n",
       "      <td>PMC3062564-36</td>\n",
       "      <td>{'RL:k78d': {'duid': 'RL:k78d', 'attribute': [...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>[22.0, 35.0]</td>\n",
       "      <td>PMC3062564</td>\n",
       "      <td>21445358</td>\n",
       "      <td>{'RL:tN3x': {'relationType': 'PHOSPHORYLATION'...</td>\n",
       "      <td>results</td>\n",
       "      <td>[{'charStart': 0, 'charEnd': 139, 'index': 0},...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To further confirm the role of c-Src in PDGF-i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    _id      article_type          docId  \\\n",
       "0  {'$oid': '5bb1845bb5e292a71605ac5c'}  research-article  PMC3062564-36   \n",
       "\n",
       "                                              entity fig_id fig_lable  id  \\\n",
       "0  {'RL:k78d': {'duid': 'RL:k78d', 'attribute': [...    NaN       NaN  36   \n",
       "\n",
       "         parent       pmcid      pmid  \\\n",
       "0  [22.0, 35.0]  PMC3062564  21445358   \n",
       "\n",
       "                                            relation sec_type  \\\n",
       "0  {'RL:tN3x': {'relationType': 'PHOSPHORYLATION'...  results   \n",
       "\n",
       "                                            sentence table_id table_lable  \\\n",
       "0  [{'charStart': 0, 'charEnd': 139, 'index': 0},...      NaN         NaN   \n",
       "\n",
       "                                                text title_offset type  \\\n",
       "0  To further confirm the role of c-Src in PDGF-i...          NaN    P   \n",
       "\n",
       "  xml_sec_type  \n",
       "0          NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pmc.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in df_pmc.itertuples():\n",
    "#     entity = item.entity\n",
    "#     sentences = item.sentence\n",
    "#     text = item.text\n",
    "#     for i in entity:\n",
    "#         a = entity[i]\n",
    "#         entityType = a['entityType']\n",
    "#         entityText = a['entityText']\n",
    "#         print(entityText)\n",
    "#         print(entityType)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing import text as T\n",
    "vectorizer = T.Tokenizer(lower=False,split=\n",
    "' ',num_words=None,char_level=False,filters=',.')\n",
    "#对文本进行词典解析\n",
    "document_after = df_pmc['text'].values\n",
    "vectorizer.fit_on_texts(document_after)\n",
    "text_sequences = vectorizer.texts_to_sequences(document_after)\n",
    "#id词对应表\n",
    "word_index = vectorizer.word_index\n",
    "index_word = vectorizer.index_word\n",
    "word_index[' '] = 0\n",
    "index_word[0] = ' '\n",
    "#词典数目\n",
    "word_vec = len(index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "#设置input_length为2000\n",
    "max_len = 2000\n",
    "#对数据进行补齐操作\n",
    "text_sequences_padded = sequence.pad_sequences(text_sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = text_sequences_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_type(_type):\n",
    "    if _type=='Protein':\n",
    "        value = 2\n",
    "    elif _type=='Trigger':\n",
    "        value = 5\n",
    "    elif _type=='SiteOther':\n",
    "        value = 4\n",
    "    elif _type=='Site':\n",
    "        value = 3\n",
    "    else:\n",
    "        value = 1\n",
    "    return value\n",
    "#对数据中文本的每个单词进行进行标注用作训练数据\n",
    "y = np.ones((text_sequences_padded.shape[0],2000))\n",
    "for i,line in enumerate(text_sequences_padded):\n",
    "    entitys = df_pmc.loc[i,'entity']\n",
    "    text_type = {}\n",
    "    for entity in entitys:\n",
    "        a = entitys[entity]\n",
    "        entityType = a['entityType']\n",
    "        entityText = a['entityText']\n",
    "        text_type[entityText] = entityType\n",
    "    for j,key in enumerate(list(line)):\n",
    "        if index_word[key] in text_type.keys():\n",
    "            type_value = text_type[index_word[key]]\n",
    "            value = set_type(type_value)\n",
    "            y[i,j] = value\n",
    "y = y.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "  warnings.warn('CRF.loss_function is deprecated '\n",
      "/anaconda3/lib/python3.6/site-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
      "  warnings.warn('CRF.accuracy is deprecated and it '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2000, 200)         126808200 \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 2000, 20)          35360     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2000, 20)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 2000, 5)           105       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2000, 5)           0         \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 2000, 5)           65        \n",
      "=================================================================\n",
      "Total params: 126,843,730\n",
      "Trainable params: 126,843,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#建立简单的bilstm+crf模型\n",
    "max_features = word_vec\n",
    "embedding_dims = 200\n",
    "sentence_length = 2000\n",
    "NUM_CLASS = 5\n",
    "DROPOUT_RATE = 0.5\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras_contrib.layers.crf import CRF\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,\n",
    "                    embedding_dims,\n",
    "                    input_length=sentence_length))\n",
    "model.add(Bidirectional(LSTM(20,return_sequences=True),merge_mode='sum'))\n",
    "model.add(Dropout(DROPOUT_RATE))\n",
    "model.add(TimeDistributed(Dense(NUM_CLASS)))\n",
    "model.add(Dropout(DROPOUT_RATE))\n",
    "#NUM_CLASS为标签数目\n",
    "crf_layer = CRF(NUM_CLASS)\n",
    "model.add(crf_layer)\n",
    "model.compile('rmsprop', loss=crf_layer.loss_function, metrics=[crf_layer.accuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对输出进行Embedding操作\n",
    "def Get_Embendding(y):\n",
    "    results = np.zeros((y.shape[0],y.shape[1],5))\n",
    "    for i,line in enumerate(y):\n",
    "        result = np.zeros((y.shape[1],5))\n",
    "        for j,key in enumerate(list(line)):\n",
    "            result[j,key-1] = 1\n",
    "        results[i] = result\n",
    "    return results\n",
    "y_embendding = Get_Embendding(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(text_sequences_padded,y_embendding,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:107: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 126808200 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 92800/116035 [======================>.......] - ETA: 31:53 - loss: 0.1495 - crf_viterbi_accuracy: 0.9387"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-451bf0c20155>\", line 1, in <module>\n",
      "    model.fit(x_train,y_train,batch_size=200,epochs=3)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 1039, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\", line 199, in fit_loop\n",
      "    outs = f(ins_batch)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2715, in __call__\n",
      "    return self._call(inputs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2675, in _call\n",
      "    fetched = self._callable_fn(*array_vals)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1439, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/anaconda3/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/anaconda3/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/anaconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/anaconda3/lib/python3.6/inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 421, in execute_request\n",
      "    self._abort_queues()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 636, in _abort_queues\n",
      "    self._abort_queue(stream)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 661, in _abort_queue\n",
      "    poller.poll(50)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/zmq/sugar/poll.py\", line 99, in poll\n",
      "    return zmq_poll(self.sockets, timeout=timeout)\n",
      "  File \"zmq/backend/cython/_poll.pyx\", line 123, in zmq.backend.cython._poll.zmq_poll\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=200,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4d42213cd169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0403bc15461f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#简易的测试\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#简易的测试\n",
    "prediction = model.predict_classes(x_test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax([i for i in prediction[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word[x_test[1][1891]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join([index_word[i] for i in x_test[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
